```markdown
# ğŸ³ Recipe Generator with Fine-Tuned GPT-2

A simple **recipe generation app** powered by a fine-tuned version of **DistilGPT-2**.  
Users can enter ingredients in a chat-like interface, and the app will generate recipe suggestions.

---

## ğŸ“‚ Project Structure

```

Task-2/
â”œâ”€â”€ data/
â”‚    â””â”€â”€ recipes.jsonl        # Training dataset
â”œâ”€â”€ models/
â”‚    â””â”€â”€ distilgpt2-recipe/   # Fine-tuned model (download separately)
â”œâ”€â”€ scripts/
â”‚    â””â”€â”€ api\_cpu.py           # FastAPI backend
â”œâ”€â”€ index.html                # Frontend chat UI
â”œâ”€â”€ style.css                 # Frontend styles
â”œâ”€â”€ script.js                 # Frontend logic
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ requirements.txt          # Python dependencies

````

---

## ğŸš€ Features
- Fine-tuned **DistilGPT-2** model for recipe generation.  
- **FastAPI backend** for serving the model.  
- **Classic chat UI** using HTML, CSS, and JavaScript.  
- Lightweight CPU-friendly deployment.

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/recipe-generator.git
cd Task-2
````

### 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate   # On Linux/Mac
.venv\Scripts\activate      # On Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ¤– Model Setup

The fine-tuned model is not stored in this repo (too large).
Download it from Google Drive:

ğŸ‘‰ [Download distilgpt2-recipe.zip](https://drive.google.com/file/d/1TaWxtSCHPI17FX-4l-iTddlbnqOmwEwu/view?usp=sharing)

After downloading:

1. Unzip the file
2. Place the folder inside:

```
Task-2/models/distilgpt2-recipe/
```

Your folder should look like:

```
Task-2/
 â”œâ”€â”€ models/
 â”‚    â””â”€â”€ distilgpt2-recipe/
 â”‚         â”œâ”€â”€ config.json
 â”‚         â”œâ”€â”€ pytorch_model.bin
 â”‚         â”œâ”€â”€ tokenizer.json
 â”‚         â””â”€â”€ ...
```

---

## â–¶ï¸ Running the Backend

Start the FastAPI server:

```bash
uvicorn scripts.api_cpu:app --reload --port 8000
```

* The backend will run on: **[http://127.0.0.1:8000](http://127.0.0.1:8000)**

---

## ğŸ’¬ Running the Frontend

Simply open `index.html` in your browser.

* Enter ingredients in the chatbox.
* The model will generate a recipe response from the backend.

---

## ğŸ›  Tech Stack

* **Python** (FastAPI, Transformers, Datasets)
* **JavaScript, HTML, CSS** (frontend)
* **Hugging Face Transformers** (model fine-tuning)

---

## ğŸ“Š Dataset

The training dataset is located in:

```
data/recipes.jsonl
```

Each entry contains:

```json
{
  "ingredients": "Chicken, Spinach, Tomato Sauce",
  "recipe": "Bake chicken breasts with spinach and tomato sauce until cooked through."
}
```
